{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - What movie to watch tonight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 14:\n",
    "+ Riccardo Ceccaroni,\n",
    "+ Angelo  Berardi,  \n",
    "+ Yifei Wei.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collector_utils file contains two functions:\n",
    "+ **data_html_to_dataframe**: that reads the links in the # .html movie files and returns a dataframe with all the links of the wikipedia pages;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_html_to_dataframe(file_name):\n",
    "    soup = bs(open(file_name), \"html.parser\")\n",
    "    wiki_links = {'idx': [],\n",
    "                  'links': []}\n",
    "\n",
    "    for tr in soup.findAll(\"tr\"):\n",
    "        for td in tr.findAll(\"td\"):\n",
    "            if 'http' in td.text:\n",
    "                wiki_links['links'].append(td.text)\n",
    "            else:\n",
    "                wiki_links['idx'].append(td.text)\n",
    "    df = pd.DataFrame(wiki_links, columns=['idx', 'links'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **save_webpage**: that saves wikipedia pages in html in the Wikipedia /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_webpage(url, file_name):\n",
    "    html = urlopen(url)\n",
    "    page_content = html.read()\n",
    "    with open('Wikipedia/' + file_name, 'wb') as fid:\n",
    "        fid.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the library collector runs a script that requires the file number and the index from which to start.\n",
    "Files are saved in the Wikipedia /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser_utils.py file contains:\n",
    "+ the function to clean up the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividi_parole(string):\n",
    "    for i in range(1, len(string) - 1):\n",
    "        if string[i - 1].islower() and string[i].isupper():\n",
    "            string = string[0:i] + \", \" + string[i:len(string)]\n",
    "        elif string[i - 1] == '.' and string[i].isupper():\n",
    "            string = string[0:i] + \", \" + string[i:len(string)]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ the parser, that collects information from the pages in the Wikipedia / directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_dict(file_name):\n",
    "    film_dict = {}\n",
    "    with open(file_name, 'rb') as html:\n",
    "        soup = bs(html, 'html.parser')\n",
    "\n",
    "    if 'This disambiguation page' in soup.text:\n",
    "        pass  # this is a disambiguation page, not film page\n",
    "    else:\n",
    "        # Title Page\n",
    "        page_title = soup.title.text\n",
    "        page_title = re.sub(r' - Wikipedia', '', page_title)\n",
    "        film_dict.update({\"Title\": page_title})\n",
    "\n",
    "        # Paragraphers (Intro and Plot)\n",
    "        p = soup.find_all(\"p\")\n",
    "\n",
    "        if len(p) >= 1:\n",
    "            intro = p[0].text\n",
    "            intro = re.sub(r'\\n', '', intro)\n",
    "            intro = re.sub(r'\\[\\d*\\]', '', intro)\n",
    "            film_dict.update({\"Intro\": intro})\n",
    "        if len(p) >= 2:\n",
    "            plot = p[1].text\n",
    "            plot = re.sub(r'\\n', '', plot)\n",
    "            plot = re.sub(r'\\[\\d*\\]', '', plot)\n",
    "            film_dict.update({\"Plot\": plot})\n",
    "\n",
    "        # URL\n",
    "        urls = soup.find(\"link\", {\"rel\": \"canonical\", 'href': True})\n",
    "        film_dict.update({\"Wikipedia Url\": urls.get('href')})\n",
    "\n",
    "        # Film Infobox\n",
    "        infobox = soup.find_all(\"table\", {\"class\": \"infobox vevent\"})\n",
    "\n",
    "        if infobox:\n",
    "            infobox = infobox[0]\n",
    "\n",
    "            tr = infobox.find_all('tr')\n",
    "\n",
    "            for i in range(len(tr)):\n",
    "                tr[i] = re.sub(r'\\[\\d*\\]', '', tr[i].text)\n",
    "                tr[i] = tr[i].replace(\"  \", \", \")\n",
    "                tr[i] = tr[i].replace(\"\\n\", \", \")\n",
    "                tr[i] = unicodedata.normalize(\"NFKD\", tr[i])\n",
    "\n",
    "                if 'Directed by' in tr[i][:11]:\n",
    "                    film_dict.update({\"Directed by\": tr[i][11:].strip(', ')})\n",
    "                elif 'Produced by' in tr[i][:11]:\n",
    "                    film_dict.update({\"Produced by\": dividi_parole(tr[i][11:].strip(', '))})\n",
    "                elif 'Written by' in tr[i][:10]:\n",
    "                    film_dict.update({\"Written by\": dividi_parole(tr[i][10:].strip(', '))})\n",
    "                elif 'Starring' in tr[i][:8]:\n",
    "                    film_dict.update({\"Starring\": dividi_parole(tr[i][8:].strip(', '))})\n",
    "                elif 'Narrated by' in tr[i][:11]:\n",
    "                    film_dict.update({\"Narrated by\": dividi_parole(tr[i][11:].strip(', '))})\n",
    "                elif 'Music by' in tr[i][:8]:\n",
    "                    film_dict.update({\"Music by\": dividi_parole(tr[i][8:].strip(', '))})\n",
    "                elif 'Screenplay by' in tr[i][:13]:\n",
    "                    film_dict.update({\"Screenplay by\": dividi_parole(tr[i][13:].strip(', '))})\n",
    "                elif 'Story by' in tr[i][:8]:\n",
    "                    film_dict.update({\"Story by\": dividi_parole(tr[i][8:].strip(', '))})\n",
    "                elif 'Cinematography' in tr[i][:14]:\n",
    "                    film_dict.update({\"Cinematography\": dividi_parole(tr[i][14:].strip(', '))})\n",
    "                elif 'Edited by' in tr[i][:9]:\n",
    "                    film_dict.update({\"Edited by\": dividi_parole(tr[i][9:].strip(', '))})\n",
    "                elif 'Productioncompany' in tr[i][:17]:\n",
    "                    film_dict.update({\"Production Company\": dividi_parole(tr[i][17:].strip(', '))})\n",
    "                elif 'Distributed by' in tr[i][:14]:\n",
    "                    film_dict.update({\"Distributed by\": dividi_parole(tr[i][14:].strip(', '))})\n",
    "                elif 'Release date' in tr[i][:12]:\n",
    "                    film_dict.update({\"Release date\": dividi_parole(tr[i][12:].strip(', '))})\n",
    "                elif 'Running time' in tr[i][:12]:\n",
    "                    film_dict.update({\"Running time\": dividi_parole(tr[i][12:].strip(', '))})\n",
    "                elif 'Country' in tr[i][:7]:\n",
    "                    film_dict.update({\"Country\": dividi_parole(tr[i][7:].strip(', '))})\n",
    "                elif 'Language' in tr[i][:8]:\n",
    "                    film_dict.update({\"Language\": dividi_parole(tr[i][8:].strip(', '))})\n",
    "                elif 'Budget' in tr[i][:6]:\n",
    "                    film_dict.update({\"Budget\": tr[i][6:].strip(', ')})\n",
    "                elif 'Box office' in tr[i][:10]:\n",
    "                    film_dict.update({\"Box office\": tr[i][10:].strip(', ')})\n",
    "                else:\n",
    "                    pass\n",
    "    return film_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ function to save all the information in a tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsv_dataframe(list_info_film):\n",
    "    dataframe = pd.DataFrame(list_info_film)\n",
    "    n_file = input(\"Number of movies file (1, 2, 3): \")\n",
    "    name_file = 'Wikipedia/tsv/movie' + n_file + '.tsv'\n",
    "    dataframe.to_csv(name_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the parser library, the parser function is launched on all the files in the Wikipedia/ directory and the user is asked to save the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index_utils.py file contains all the functions to clean up the text, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    text = text.lower()\n",
    "    text = tokenizer(text)\n",
    "    text = remove_stop_word(text)\n",
    "    text = word_lemmatizer(text)\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and create a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocabulary_df(dataframe_df):\n",
    "    vocabulary = list(set((' '.join(dataframe_df['Intro+Plot'].tolist())).split(' ')))\n",
    "    vocabulary.remove('')\n",
    "    vocabulary = pd.DataFrame(vocabulary, columns=['Word'])\n",
    "    vocabulary.to_json(r'Json\\vocabulary.json', index=False, orient='table')\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index.py file contains the class that define an index, with the function for search file and create scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    \"\"\"\n",
    "    Inverted Index class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation of the Database object\n",
    "        \"\"\"\n",
    "        return str(self.index)\n",
    "\n",
    "    def index_document(self, document):\n",
    "        \"\"\"\n",
    "        Process a given document, save it to the DB and update the index.\n",
    "        \"\"\"\n",
    "\n",
    "        # Remove punctuation from the text.\n",
    "        clean_text = index_utils.format_text(document['text'])\n",
    "        terms = clean_text.split(' ')\n",
    "        appearances_dict = dict()\n",
    "        # Dictionary with each term and the frequency it appears in the text.\n",
    "        for term in terms:\n",
    "            term_frequency = appearances_dict[term]['frequency'] if term in appearances_dict else 0\n",
    "            appearances_dict[term] = {'docId': document['id'], 'frequency': (term_frequency + 1)}\n",
    "\n",
    "        # Update the inverted index\n",
    "        update_dict = {key: [appearance]\n",
    "                       if key not in self.index\n",
    "                       else self.index[key] + [appearance]\n",
    "                       for (key, appearance) in appearances_dict.items()}\n",
    "        self.index.update(update_dict)\n",
    "        # Add the document into the database\n",
    "        return document\n",
    "\n",
    "    def lookup_conjunctive_query(self, query):\n",
    "        try:\n",
    "            with open(r'Json\\inverted_index_dict.json', 'r') as f:\n",
    "                self.index = json.load(f)\n",
    "        except:\n",
    "            print(\"Load Error Database\")\n",
    "        r = {}\n",
    "        for term in query.split(' '):\n",
    "            if term in self.index:\n",
    "                r.update({term: self.index[term]})\n",
    "            else:\n",
    "                r.update({term: []})\n",
    "        j = 0\n",
    "        l = []\n",
    "        for d in r:\n",
    "            t = []\n",
    "            for i in range(len(r[d])):\n",
    "                t.append(r[d][i]['docId'])\n",
    "            l.append(set(t))\n",
    "            j += 1\n",
    "        idx_set = l[0]\n",
    "        for i in range(1, len(l)):\n",
    "            idx_set = idx_set.intersection(l[i])\n",
    "\n",
    "        return dataframe[['Title', 'Intro', 'Wikipedia Url']].iloc[list(idx_set)].reset_index(drop=True)\n",
    "\n",
    "    def generate_tfidf(self):\n",
    "        D = len(dataframe_df[['Intro+Plot']])\n",
    "        for word in self.index:\n",
    "            d = len(self.index[word])\n",
    "            for doc_dict in self.index[word]:\n",
    "                tfidf = (doc_dict['frequency'] / len(dataframe_df['Intro+Plot'].iloc[doc_dict['docId']].split(\" \"))) * (1 + log(D/d))\n",
    "                doc_dict['tfidf'] = tfidf\n",
    "        with open(r'Json\\inverted_index_tfidf.json', 'w') as f:\n",
    "            json.dump(self.index, f)\n",
    "\n",
    "    def lookup_conjunctive_query_and_ranking_score(self, query):\n",
    "        # import inverted index tfidf database\n",
    "        try:\n",
    "            with open(r'Json\\inverted_index_tfidf.json', 'r') as f:\n",
    "                self.index = json.load(f)\n",
    "        except:\n",
    "            with open(r'Json\\inverted_index_dict.json', 'r') as f:\n",
    "                self.index = json.load(f)\n",
    "            self.generate_tfidf()\n",
    "            with open(r'Json\\inverted_index_tfidf.json', 'r') as f:\n",
    "                self.index = json.load(f)\n",
    "\n",
    "        index_for_query = {term: self.index[term] for term in query.split(' ') if term in self.index}\n",
    "\n",
    "        # calculate tfidf for query\n",
    "        query_tfidf = []\n",
    "        query_split = query.split(' ')\n",
    "        tf = 1 / len(query_split)\n",
    "        for word in query_split:\n",
    "            try:\n",
    "                idf = 1 + log(len(dataframe_df[['Intro+Plot']])/len(self.index[word]))\n",
    "            except:\n",
    "                idf = 1\n",
    "            query_tfidf.append({'word': word, 'tfidf': tf*idf})\n",
    "\n",
    "        # calculate cosine similarity\n",
    "        ## index -> dataframe\n",
    "        index_for_query_df = {word: {doc_dict['docId']: doc_dict['tfidf'] for doc_dict in index_for_query[word]}\n",
    "                              for word in index_for_query}\n",
    "        index_for_query_df = pd.DataFrame(index_for_query_df).fillna(0)\n",
    "\n",
    "        ## Cosine similarity\n",
    "        col_list = list(index_for_query_df)\n",
    "\n",
    "        index_for_query_df.loc[:, 'den'] = ((index_for_query_df.loc[:, col_list] ** 2)[col_list].sum(axis=1)) ** (1/2)\n",
    "        index_for_query_df.loc[:, 'num'] = 0\n",
    "        query_mod = 0\n",
    "\n",
    "        for i in range(len(query_tfidf)):\n",
    "            if query_tfidf[i]['word'] in index_for_query_df:\n",
    "                index_for_query_df.loc[:, 'num'] += index_for_query_df.loc[:, query_tfidf[i]['word']] * query_tfidf[i]['tfidf']\n",
    "            query_mod += (query_tfidf[i]['tfidf'] ** 2)\n",
    "        query_mod = sqrt(query_mod)\n",
    "        index_for_query_df.loc[:, 'den'] *= query_mod\n",
    "        index_for_query_df.loc[:, 'Similarity'] = index_for_query_df.loc[:, 'num'] / index_for_query_df.loc[:, 'den']\n",
    "        df_similarity = pd.merge(dataframe[['Title', 'Intro', 'Wikipedia Url']], index_for_query_df[['Similarity']],\n",
    "                                 left_index=True, right_index=True, sort=True)\n",
    "        df_similarity = df_similarity.sort_values(by=['Similarity'], ascending=False)\n",
    "\n",
    "        return df_similarity[df_similarity['Similarity'] >= 0.75].reset_index(drop=True)\n",
    "\n",
    "    def save_inverted_index(self):\n",
    "        with open(r'Json\\inverted_index_dict.json', 'w') as f:\n",
    "            json.dump(self.index, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **generate_tfidf** generates the tf index and idf index:\n",
    "<p>The <b>TF</b> (term frequency) is defined as:</p> \n",
    "\n",
    "<p>$TF = n_w/N_w$</p>\n",
    "\n",
    "<p>where $n_w$ is the number of occurences of the word in document, and $N_w$ the total number of words in the document.</p>\n",
    "\n",
    "<p>while the <b>IDF</b> (inverse document frequency) is:</p>\n",
    "\n",
    "<p>$IDF = 1 + log_{10}\\left(\\frac{N_d}{n_d}\\right)$</p>\n",
    "\n",
    "<p>where $N_d$ is the total number of documents and $n_d$ the number of documents containing the word</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main.py file an object InvertedIndex is created and with this the requests for research are managed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import index\n",
    "import index_utils\n",
    "\n",
    "\n",
    "inverted_index = index.InvertedIndex(index.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter term(s) to search:  Disney Movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Wikipedia Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Under Wraps (film)</td>\n",
       "      <td>Under Wraps is a 1997 television film directed...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Under_Wraps_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Annie (1982 film)</td>\n",
       "      <td>Annie is a 1982 American musical comedy-drama ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Annie_(1982_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Summer Magic</td>\n",
       "      <td>Summer Magic is a 1963 Walt Disney Productions...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Summer_Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Last Starfighter</td>\n",
       "      <td>The Last Starfighter is a 1984 American space ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Last_Starfig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Cat Concerto</td>\n",
       "      <td>The Cat Concerto is a 1947 American one-reel a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Cat_Concerto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Machine Gun Mama</td>\n",
       "      <td>Machine Gun Mama is a 1944 American musical co...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Machine_Gun_Mama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Rango (2011 film)</td>\n",
       "      <td>Rango is a 2011 American computer-animated wes...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rango_(2011_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Northern Lights (1997 film)</td>\n",
       "      <td>Northern Lights is a 1997 television film base...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Northern_Lights_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>WALL-E</td>\n",
       "      <td>WALL-E (stylized with an interpunct as WALL·E)...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/WALL-E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>The Rugrats Movie</td>\n",
       "      <td>The Rugrats Movie is a 1998 American animated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Rugrats_Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Tex (film)</td>\n",
       "      <td>Tex is a 1982 American drama film directed by ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tex_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Sullivan's Travels</td>\n",
       "      <td>Sullivan's Travels is a 1941 American comedy f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sullivan%27s_Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Chronicles_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>She (1935 film)</td>\n",
       "      <td>She is a 1935 American film produced by Merian...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/She_(1935_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>The Avengers (2012 film)</td>\n",
       "      <td>Marvel's The Avengers (classified under the na...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Avengers_(20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0                         Under Wraps (film)   \n",
       "1                          Annie (1982 film)   \n",
       "2                               Summer Magic   \n",
       "3                       The Last Starfighter   \n",
       "4                           The Cat Concerto   \n",
       "5                           Machine Gun Mama   \n",
       "6                          Rango (2011 film)   \n",
       "7                Northern Lights (1997 film)   \n",
       "8                                     WALL-E   \n",
       "9                          The Rugrats Movie   \n",
       "10                                Tex (film)   \n",
       "11                        Sullivan's Travels   \n",
       "12  The Chronicles of Narnia: Prince Caspian   \n",
       "13                           She (1935 film)   \n",
       "14                  The Avengers (2012 film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0   Under Wraps is a 1997 television film directed...   \n",
       "1   Annie is a 1982 American musical comedy-drama ...   \n",
       "2   Summer Magic is a 1963 Walt Disney Productions...   \n",
       "3   The Last Starfighter is a 1984 American space ...   \n",
       "4   The Cat Concerto is a 1947 American one-reel a...   \n",
       "5   Machine Gun Mama is a 1944 American musical co...   \n",
       "6   Rango is a 2011 American computer-animated wes...   \n",
       "7   Northern Lights is a 1997 television film base...   \n",
       "8   WALL-E (stylized with an interpunct as WALL·E)...   \n",
       "9   The Rugrats Movie is a 1998 American animated ...   \n",
       "10  Tex is a 1982 American drama film directed by ...   \n",
       "11  Sullivan's Travels is a 1941 American comedy f...   \n",
       "12  The Chronicles of Narnia: Prince Caspian is a ...   \n",
       "13  She is a 1935 American film produced by Merian...   \n",
       "14  Marvel's The Avengers (classified under the na...   \n",
       "\n",
       "                                        Wikipedia Url  \n",
       "0    https://en.wikipedia.org/wiki/Under_Wraps_(film)  \n",
       "1     https://en.wikipedia.org/wiki/Annie_(1982_film)  \n",
       "2          https://en.wikipedia.org/wiki/Summer_Magic  \n",
       "3   https://en.wikipedia.org/wiki/The_Last_Starfig...  \n",
       "4      https://en.wikipedia.org/wiki/The_Cat_Concerto  \n",
       "5      https://en.wikipedia.org/wiki/Machine_Gun_Mama  \n",
       "6     https://en.wikipedia.org/wiki/Rango_(2011_film)  \n",
       "7   https://en.wikipedia.org/wiki/Northern_Lights_...  \n",
       "8                https://en.wikipedia.org/wiki/WALL-E  \n",
       "9     https://en.wikipedia.org/wiki/The_Rugrats_Movie  \n",
       "10           https://en.wikipedia.org/wiki/Tex_(film)  \n",
       "11  https://en.wikipedia.org/wiki/Sullivan%27s_Tra...  \n",
       "12  https://en.wikipedia.org/wiki/The_Chronicles_o...  \n",
       "13      https://en.wikipedia.org/wiki/She_(1935_film)  \n",
       "14  https://en.wikipedia.org/wiki/The_Avengers_(20...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = input(\"Enter term(s) to search: \")\n",
    "inverted_index.lookup_conjunctive_query(index_utils.format_text(search_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter term(s) to search:  Disney Movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Wikipedia Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Rugrats Movie</td>\n",
       "      <td>The Rugrats Movie is a 1998 American animated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Rugrats_Movie</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WALL-E</td>\n",
       "      <td>WALL-E (stylized with an interpunct as WALL·E)...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/WALL-E</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Last Starfighter</td>\n",
       "      <td>The Last Starfighter is a 1984 American space ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Last_Starfig...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Annie (1982 film)</td>\n",
       "      <td>Annie is a 1982 American musical comedy-drama ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Annie_(1982_film)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Avengers (2012 film)</td>\n",
       "      <td>Marvel's The Avengers (classified under the na...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Avengers_(20...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The Cat Concerto</td>\n",
       "      <td>The Cat Concerto is a 1947 American one-reel a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Cat_Concerto</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>She (1935 film)</td>\n",
       "      <td>She is a 1935 American film produced by Merian...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/She_(1935_film)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Rango (2011 film)</td>\n",
       "      <td>Rango is a 2011 American computer-animated wes...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rango_(2011_film)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Machine Gun Mama</td>\n",
       "      <td>Machine Gun Mama is a 1944 American musical co...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Machine_Gun_Mama</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Sullivan's Travels</td>\n",
       "      <td>Sullivan's Travels is a 1941 American comedy f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sullivan%27s_Tra...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Tex (film)</td>\n",
       "      <td>Tex is a 1982 American drama film directed by ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tex_(film)</td>\n",
       "      <td>0.952574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Under Wraps (film)</td>\n",
       "      <td>Under Wraps is a 1997 television film directed...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Under_Wraps_(film)</td>\n",
       "      <td>0.952574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Summer Magic</td>\n",
       "      <td>Summer Magic is a 1963 Walt Disney Productions...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Summer_Magic</td>\n",
       "      <td>0.904749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Chronicles_o...</td>\n",
       "      <td>0.872853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Northern Lights (1997 film)</td>\n",
       "      <td>Northern Lights is a 1997 television film base...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Northern_Lights_...</td>\n",
       "      <td>0.835479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0                          The Rugrats Movie   \n",
       "1                                     WALL-E   \n",
       "2                       The Last Starfighter   \n",
       "3                          Annie (1982 film)   \n",
       "4                   The Avengers (2012 film)   \n",
       "5                           The Cat Concerto   \n",
       "6                            She (1935 film)   \n",
       "7                          Rango (2011 film)   \n",
       "8                           Machine Gun Mama   \n",
       "9                         Sullivan's Travels   \n",
       "10                                Tex (film)   \n",
       "11                        Under Wraps (film)   \n",
       "12                              Summer Magic   \n",
       "13  The Chronicles of Narnia: Prince Caspian   \n",
       "14               Northern Lights (1997 film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0   The Rugrats Movie is a 1998 American animated ...   \n",
       "1   WALL-E (stylized with an interpunct as WALL·E)...   \n",
       "2   The Last Starfighter is a 1984 American space ...   \n",
       "3   Annie is a 1982 American musical comedy-drama ...   \n",
       "4   Marvel's The Avengers (classified under the na...   \n",
       "5   The Cat Concerto is a 1947 American one-reel a...   \n",
       "6   She is a 1935 American film produced by Merian...   \n",
       "7   Rango is a 2011 American computer-animated wes...   \n",
       "8   Machine Gun Mama is a 1944 American musical co...   \n",
       "9   Sullivan's Travels is a 1941 American comedy f...   \n",
       "10  Tex is a 1982 American drama film directed by ...   \n",
       "11  Under Wraps is a 1997 television film directed...   \n",
       "12  Summer Magic is a 1963 Walt Disney Productions...   \n",
       "13  The Chronicles of Narnia: Prince Caspian is a ...   \n",
       "14  Northern Lights is a 1997 television film base...   \n",
       "\n",
       "                                        Wikipedia Url  Similarity  \n",
       "0     https://en.wikipedia.org/wiki/The_Rugrats_Movie    1.000000  \n",
       "1                https://en.wikipedia.org/wiki/WALL-E    1.000000  \n",
       "2   https://en.wikipedia.org/wiki/The_Last_Starfig...    1.000000  \n",
       "3     https://en.wikipedia.org/wiki/Annie_(1982_film)    1.000000  \n",
       "4   https://en.wikipedia.org/wiki/The_Avengers_(20...    1.000000  \n",
       "5      https://en.wikipedia.org/wiki/The_Cat_Concerto    1.000000  \n",
       "6       https://en.wikipedia.org/wiki/She_(1935_film)    1.000000  \n",
       "7     https://en.wikipedia.org/wiki/Rango_(2011_film)    1.000000  \n",
       "8      https://en.wikipedia.org/wiki/Machine_Gun_Mama    1.000000  \n",
       "9   https://en.wikipedia.org/wiki/Sullivan%27s_Tra...    1.000000  \n",
       "10           https://en.wikipedia.org/wiki/Tex_(film)    0.952574  \n",
       "11   https://en.wikipedia.org/wiki/Under_Wraps_(film)    0.952574  \n",
       "12         https://en.wikipedia.org/wiki/Summer_Magic    0.904749  \n",
       "13  https://en.wikipedia.org/wiki/The_Chronicles_o...    0.872853  \n",
       "14  https://en.wikipedia.org/wiki/Northern_Lights_...    0.835479  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = input(\"Enter term(s) to search: \")\n",
    "inverted_index.lookup_conjunctive_query_and_ranking_score(index_utils.format_text(search_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined a new score with this algorithm:\n",
    "\n",
    "**Jaccard similitude:** The Jaccard index, also known as Intersection over Union and the Jaccard similarity coefficient (originally given the French name coefficient de communauté by Paul Jaccard), is a statistic used for gauging the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets:\n",
    "\n",
    "$J(A,B) = {{|A \\cap B|}\\over{|A \\cup B|}} = {{|A \\cap B|}\\over{|A| + |B| - |A \\cap B|}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the index.py file there is the function define_new_score(query, k) that take as input 'query', the subject to search, and k as biggest number all the results of the research. The function search by 'Title', 'Written by', 'Directed by', 'Distributed by'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_new_score(query, k):\n",
    "    # Trovare per cosa cercare + ripulire testo\n",
    "    heap = []\n",
    "    try:\n",
    "        what = pd.read_json(r'Json\\dataframe_format_all.json', orient='table')\n",
    "    except:\n",
    "        what = index_utils.generate_format_for_new_score(dataframe)\n",
    "\n",
    "    what = what[['All']]\n",
    "    format_query = index_utils.format_text(query)\n",
    "\n",
    "    for i in range(len(what)):\n",
    "        heapq.heappush(heap, [index_utils.get_jaccard_sim(format_query, str(what.iloc[i])), i])\n",
    "    result = {int(x[1]): float(x[0])for x in heapq.nlargest(k, heap) if float(x[0]) > 0}\n",
    "\n",
    "    if result:\n",
    "        new_score_df = pd.DataFrame(heapq.nlargest(k, heap), columns=['Similarity', 'idx'])\n",
    "        df_similarity = pd.merge(dataframe[['Title', 'Intro', 'Wikipedia Url']], new_score_df[['Similarity', 'idx']],\n",
    "                                 left_index=True, right_on='idx', sort=True)\n",
    "        df_similarity = df_similarity.sort_values(by=['Similarity'], ascending=False)\n",
    "        return df_similarity[['Title', 'Intro', 'Wikipedia Url', 'Similarity']]\n",
    "    else:\n",
    "        return 'Not Found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import index\n",
    "import index_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter term(s) to search:  Alice in wonderland\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter term(s) to search: \")\n",
    "result, actor = index.define_new_score(search_term, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Charlotte Henry', ' W. C. Fields', ' Richard Arlen', ' Edna May Oliver', ' Cary Grant', ' Gary Cooper', ' Edward Everett Horton', ' Baby Le', ' Roy'], ['Kathryn Beaumont', ' Ed Wynn', ' Richard Haydn', ' Sterling Holloway', ' Jerry Colonna', ' Verna Felton', \" J. Pat O'Malley\", ' Bill Thompson', ' Joseph Kearns', ' Dink Trout', ' James Mac', ' Donald'], ['Johnny Depp', ' Anne Hathaway', ' Helena Bonham Carter', ' Crispin Glover', ' Matt Lucas', ' Mia Wasikowska', ' Alan Rickman', ' Stephen Fry', ' Michael Sheen', ' Timothy Spall'], ['May Clark', ' Cecil M. Hepworth', ' Mrs. Cecil Hepworth', ' Norman Whitten'], ['Natalie Gregory', ' Red Buttons', ' Anthony Newley', ' Jayne Meadows', ' Carol Channing', ' Roddy  Dowall', ' Ann Jillian', ' Pat MoritaRobert Morley'], ['Jayaram', ' Vineeth', ' SandhyaLaya'], ['Ellen Burstyn', ' Kris Kristofferson', ' Diane Ladd', ' Jodie Foster', ' Alfred Lutter'], ['Linda Miller', ' Mildred Clinton', ' Paula Sheppard', ' Niles  Master', ' Brooke Shields'], ['Meryl Streep', ' Kurt Russell', ' Cher'], ['Gemma Arterton', ' Martin Compston', ' Eddie Marsan']]\n"
     ]
    }
   ],
   "source": [
    "utils.print_actor(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Wikipedia Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Alice in Wonderland (1933 film)</td>\n",
       "      <td>Alice in Wonderland is a 1933 American pre-Cod...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Alice in Wonderland (1951 film)</td>\n",
       "      <td>Alice in Wonderland is a 1951 American animate...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alice in Wonderland (2010 film)</td>\n",
       "      <td>Alice in Wonderland is a 2010 American dark fa...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Alice in Wonderland (1903 film)</td>\n",
       "      <td>Alice in Wonderland is a 1903 British silent f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Alice in Wonderland (1985 film)</td>\n",
       "      <td>Alice in Wonderland is a 1985 two-part made-fo...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Alice in Wonderland (2005 film)</td>\n",
       "      <td>Alice in Wonderland is a 2005 Malayalam langua...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Alice Doesn't Live Here Anymore</td>\n",
       "      <td>Alice Doesn't Live Here Anymore is a 1974 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_Doesn%27t_...</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Alice, Sweet Alice</td>\n",
       "      <td>Alice, Sweet Alice (originally titled Communio...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice,_Sweet_Alice</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Silkwood</td>\n",
       "      <td>Silkwood is a 1983 American biographical drama...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Silkwood</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>The Disappearance of Alice Creed</td>\n",
       "      <td>The Disappearance of Alice Creed  is a 2009 Br...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Disappearanc...</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "2   Alice in Wonderland (1933 film)   \n",
       "1   Alice in Wonderland (1951 film)   \n",
       "0   Alice in Wonderland (2010 film)   \n",
       "5   Alice in Wonderland (1903 film)   \n",
       "4   Alice in Wonderland (1985 film)   \n",
       "3   Alice in Wonderland (2005 film)   \n",
       "9   Alice Doesn't Live Here Anymore   \n",
       "8                Alice, Sweet Alice   \n",
       "7                          Silkwood   \n",
       "6  The Disappearance of Alice Creed   \n",
       "\n",
       "                                               Intro  \\\n",
       "2  Alice in Wonderland is a 1933 American pre-Cod...   \n",
       "1  Alice in Wonderland is a 1951 American animate...   \n",
       "0  Alice in Wonderland is a 2010 American dark fa...   \n",
       "5  Alice in Wonderland is a 1903 British silent f...   \n",
       "4  Alice in Wonderland is a 1985 two-part made-fo...   \n",
       "3  Alice in Wonderland is a 2005 Malayalam langua...   \n",
       "9  Alice Doesn't Live Here Anymore is a 1974 Amer...   \n",
       "8  Alice, Sweet Alice (originally titled Communio...   \n",
       "7  Silkwood is a 1983 American biographical drama...   \n",
       "6  The Disappearance of Alice Creed  is a 2009 Br...   \n",
       "\n",
       "                                       Wikipedia Url  Similarity  \n",
       "2  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.166667  \n",
       "1  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.166667  \n",
       "0  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.166667  \n",
       "5  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.153846  \n",
       "4  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.153846  \n",
       "3  https://en.wikipedia.org/wiki/Alice_in_Wonderl...    0.153846  \n",
       "9  https://en.wikipedia.org/wiki/Alice_Doesn%27t_...    0.090909  \n",
       "8   https://en.wikipedia.org/wiki/Alice,_Sweet_Alice    0.090909  \n",
       "7             https://en.wikipedia.org/wiki/Silkwood    0.090909  \n",
       "6  https://en.wikipedia.org/wiki/The_Disappearanc...    0.090909  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithmic question\n",
    "You are given a string, s. Let's define a subsequence as the subset of characters that respects the order we find them in s. For instance, a subsequence of \"DATAMINING\" is \"TMNN\". Your goal is to define and implement an algorithm that finds the length of the longest possible subsequence that can be read in the same way forward and backwards. For example, given the string \"DATAMININGSAPIENZA\" the answer should be 7 (dAtamININgsapIenzA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert string:  dataminingsapienza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def algorithm_palindrome_sub_string_len(string, idx_start, idx_end):\n",
    "    \"\"\"\n",
    "    recursive algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    if idx_end < idx_start:\n",
    "        return 0\n",
    "    if idx_end == idx_start:\n",
    "        return 1\n",
    "    if string[idx_start] == string[idx_end]:\n",
    "        return algorithm_palindrome_sub_string_len(string, idx_start+1, idx_end-1) + 2\n",
    "    right = algorithm_palindrome_sub_string_len(string, idx_start+1, idx_end)\n",
    "    left = algorithm_palindrome_sub_string_len(string, idx_start, idx_end-1)\n",
    "\n",
    "    if right > left:\n",
    "        return right\n",
    "    else:\n",
    "        return left\n",
    "\n",
    "\n",
    "def palindrome_sub_string_len(string):\n",
    "    return algorithm_palindrome_sub_string_len(string, 0, len(string)-1)\n",
    "\n",
    "\n",
    "print(palindrome_sub_string_len(input('Insert string: ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
